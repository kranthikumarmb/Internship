{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d4b35d8",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "0d2ac882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required li\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "038c08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32.exe')\n",
    "d.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "d.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "7c3ff154",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "upload_date=[]\n",
    "views=[]\n",
    "na=d.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[1]')[0:30]# we are taking the data from the child class\n",
    "for i in na:\n",
    "    nam=i.text\n",
    "    rank.append(nam)\n",
    "na=d.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[2]')[0:30]\n",
    "for i in na:\n",
    "    nam=i.text\n",
    "    name.append(nam)    \n",
    "na=d.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')[0:30]\n",
    "for i in na:\n",
    "    nam=i.text\n",
    "    artist.append(nam)\n",
    "na=d.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')[0:30]\n",
    "for i in na:\n",
    "    nam=i.text\n",
    "    upload_date.append(nam)    \n",
    "na=d.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[4]')[0:30]\n",
    "for i in na:\n",
    "    nam=i.text\n",
    "    views.append(nam)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "89167e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank of the song</th>\n",
       "      <th>Name of the song</th>\n",
       "      <th>Name of the artist</th>\n",
       "      <th>Uploaded date</th>\n",
       "      <th>Views of teh video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[16]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[24]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Wheels on the Bus\"[25]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[26]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[34]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[35]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[36]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"[39]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[42]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Faded\"[43]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[44]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Girls Like You\"[45]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[50]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank of the song                                Name of the song   \\\n",
       "0                1.                            \"Baby Shark Dance\"[4]   \n",
       "1                2.                                   \"Despacito\"[7]   \n",
       "2                3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3                4.                                  \"Bath Song\"[15]   \n",
       "4                5.                               \"Shape of You\"[16]   \n",
       "5                6.                              \"See You Again\"[18]   \n",
       "6                7.                \"Phonics Song with Two Words\"[23]   \n",
       "7                8.                                \"Uptown Funk\"[24]   \n",
       "8                9.                          \"Wheels on the Bus\"[25]   \n",
       "9               10.  \"Learning Colors – Colorful Eggs on a Farm\"[26]   \n",
       "10              11.                              \"Gangnam Style\"[27]   \n",
       "11              12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12              13.                             \"Dame Tu Cosita\"[33]   \n",
       "13              14.                                      \"Sugar\"[34]   \n",
       "14              15.                                       \"Roar\"[35]   \n",
       "15              16.                             \"Counting Stars\"[36]   \n",
       "16              17.                                     \"Axel F\"[37]   \n",
       "17              18.                                      \"Sorry\"[38]   \n",
       "18              19.                          \"Thinking Out Loud\"[39]   \n",
       "19              20.                        \"Baa Baa Black Sheep\"[40]   \n",
       "20              21.                                 \"Dark Horse\"[41]   \n",
       "21              22.           \"Waka Waka (This Time for Africa)\"[42]   \n",
       "22              23.                                      \"Faded\"[43]   \n",
       "23              24.                                 \"Let Her Go\"[44]   \n",
       "24              25.                             \"Girls Like You\"[45]   \n",
       "25              26.                                    \"Perfect\"[46]   \n",
       "26              27.                                   \"Bailando\"[47]   \n",
       "27              28.                                    \"Lean On\"[48]   \n",
       "28              29.          \"Humpty the train on a fruits ride\"[49]   \n",
       "29              30.                             \"Lakdi Ki Kathi\"[50]   \n",
       "\n",
       "                               Name of the artist     Uploaded date   \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                      Luis Fonsi   January 12, 2017   \n",
       "2                                     LooLoo Kids    October 8, 2016   \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "4                                      Ed Sheeran   January 30, 2017   \n",
       "5                                     Wiz Khalifa      April 6, 2015   \n",
       "6                                       ChuChu TV      March 6, 2014   \n",
       "7                                     Mark Ronson  November 19, 2014   \n",
       "8                      Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "9                                     Miroshka TV  February 27, 2018   \n",
       "10                                            Psy      July 15, 2012   \n",
       "11                                     Get Movies   January 31, 2012   \n",
       "12                                      El Chombo      April 5, 2018   \n",
       "13                                       Maroon 5   January 14, 2015   \n",
       "14                                     Katy Perry  September 5, 2013   \n",
       "15                                    OneRepublic       May 31, 2013   \n",
       "16                                     Crazy Frog      June 16, 2009   \n",
       "17                                  Justin Bieber   October 22, 2015   \n",
       "18                                     Ed Sheeran    October 7, 2014   \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "20                                     Katy Perry  February 20, 2014   \n",
       "21                                        Shakira       June 4, 2010   \n",
       "22                                    Alan Walker   December 3, 2015   \n",
       "23                                      Passenger      July 25, 2012   \n",
       "24                                       Maroon 5       May 31, 2018   \n",
       "25                                     Ed Sheeran   November 9, 2017   \n",
       "26                               Enrique Iglesias     April 11, 2014   \n",
       "27                                    Major Lazer     March 22, 2015   \n",
       "28  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "29                                   Jingle Toons      June 14, 2018   \n",
       "\n",
       "   Views of teh video  \n",
       "0               12.00  \n",
       "1                8.05  \n",
       "2                6.57  \n",
       "3                5.89  \n",
       "4                5.88  \n",
       "5                5.74  \n",
       "6                5.08  \n",
       "7                4.79  \n",
       "8                4.77  \n",
       "9                4.76  \n",
       "10               4.64  \n",
       "11               4.52  \n",
       "12               4.18  \n",
       "13               3.80  \n",
       "14               3.70  \n",
       "15               3.70  \n",
       "16               3.67  \n",
       "17               3.62  \n",
       "18               3.53  \n",
       "19               3.46  \n",
       "20               3.42  \n",
       "21               3.40  \n",
       "22               3.38  \n",
       "23               3.36  \n",
       "24               3.35  \n",
       "25               3.33  \n",
       "26               3.31  \n",
       "27               3.31  \n",
       "28               3.26  \n",
       "29               3.24  "
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank of the song':rank,'Name of the song ':name,'Name of the artist':artist,'Uploaded date ':upload_date,'Views of teh video':views})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c96d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a24f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53367a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe716231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc431d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09454a8b",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1\n",
    "st ODI)\n",
    "\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86848b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libabries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6e54c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32.exe')\n",
    "d.get('https://www.bcci.tv/.')\n",
    "d.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7deda587",
   "metadata": {},
   "outputs": [],
   "source": [
    "internatl=d.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "internatl.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c090a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_title=[]\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time=[]\n",
    "titl=d.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "for i in titl:\n",
    "    ti=i.text\n",
    "    match_title.append(ti)\n",
    "dat=d.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]')\n",
    "for l in dat:\n",
    "    da=l.text\n",
    "    date.append(da)\n",
    "tie=d.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]') \n",
    "for w in tie:\n",
    "    tim=w.text\n",
    "    time.append(tim)\n",
    "pl=d.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]') \n",
    "for g in pl:\n",
    "    pla=g.text.split('-')[1]\n",
    "    place.append(pla)\n",
    "seri=d.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]') \n",
    "for b in seri:\n",
    "    serie=b.text.split('-')[0]\n",
    "    series.append(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "558c23ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19</td>\n",
       "      <td>4th T20I</td>\n",
       "      <td>Steyn City School Ground, Pretoria</td>\n",
       "      <td>2 JAN 2023</td>\n",
       "      <td>5:15 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Wankhede Stadium, Mumbai</td>\n",
       "      <td>3 JAN 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19</td>\n",
       "      <td>5th T20I</td>\n",
       "      <td>Steyn City School Ground, Pretoria</td>\n",
       "      <td>4 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>Maharashtra Cricket Association Stadium, Pune</td>\n",
       "      <td>5 JAN 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>Saurashtra Cricket Association Stadium, Rajkot</td>\n",
       "      <td>7 JAN 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SRI LANKA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>1st ODI</td>\n",
       "      <td>Barsapara Cricket Stadium, Guwahati</td>\n",
       "      <td>10 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SRI LANKA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>Eden Gardens, Kolkata</td>\n",
       "      <td>12 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SRI LANKA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>Greenfield International Stadium, Thiruvanant...</td>\n",
       "      <td>15 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Match Title     Series  \\\n",
       "0  INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19  4th T20I    \n",
       "1      SRI LANKA TOUR OF INDIA T20 SERIES 2022-23  1st T20I    \n",
       "2  INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19  5th T20I    \n",
       "3      SRI LANKA TOUR OF INDIA T20 SERIES 2022-23  2nd T20I    \n",
       "4      SRI LANKA TOUR OF INDIA T20 SERIES 2022-23  3rd T20I    \n",
       "5      SRI LANKA TOUR OF INDIA ODI SERIES 2022-23   1st ODI    \n",
       "6      SRI LANKA TOUR OF INDIA ODI SERIES 2022-23   2nd ODI    \n",
       "7      SRI LANKA TOUR OF INDIA ODI SERIES 2022-23   3rd ODI    \n",
       "\n",
       "                                               Place         Date         Time  \n",
       "0                 Steyn City School Ground, Pretoria   2 JAN 2023  5:15 PM IST  \n",
       "1                           Wankhede Stadium, Mumbai   3 JAN 2023  7:00 PM IST  \n",
       "2                 Steyn City School Ground, Pretoria   4 JAN 2023  1:30 PM IST  \n",
       "3      Maharashtra Cricket Association Stadium, Pune   5 JAN 2023  7:00 PM IST  \n",
       "4     Saurashtra Cricket Association Stadium, Rajkot   7 JAN 2023  7:00 PM IST  \n",
       "5                Barsapara Cricket Stadium, Guwahati  10 JAN 2023  1:30 PM IST  \n",
       "6                              Eden Gardens, Kolkata  12 JAN 2023  1:30 PM IST  \n",
       "7   Greenfield International Stadium, Thiruvanant...  15 JAN 2023  1:30 PM IST  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Match Title':match_title,'Series':series,'Place':place,'Date':date,'Time':time})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287499f6",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "3ae03eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libabries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "46e0c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32.exe')\n",
    "d.get('https://www.guru99.com/')\n",
    "d.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "62489500",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=d.find_element(By.XPATH,'//input[@class=\"gsc-input\"]')\n",
    "search_bar.send_keys('selenium exception handling ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "7002f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=d.find_element(By.XPATH,'//button[@class=\"gsc-search-button gsc-search-button-v2\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "c54f1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=d.find_element(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div[1]/div[1]/div[2]/div/div[1]/div/div/div/div[1]/div[6]/div[2]/div/div/div[1]/div[1]/div[1]/div[1]/div/a')\n",
    "path.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "6a1a6be1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/div/div/div/main/div/article/div/div/p[8]\"}\n  (Session info: chrome=108.0.5359.125)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x0051F243]\n\t(No symbol) [0x004A7FD1]\n\t(No symbol) [0x0039D04D]\n\t(No symbol) [0x003CC0B0]\n\t(No symbol) [0x003CC22B]\n\t(No symbol) [0x003FE612]\n\t(No symbol) [0x003E85D4]\n\t(No symbol) [0x003FC9EB]\n\t(No symbol) [0x003E8386]\n\t(No symbol) [0x003C163C]\n\t(No symbol) [0x003C269D]\n\tGetHandleVerifier [0x007B9A22+2655074]\n\tGetHandleVerifier [0x007ACA24+2601828]\n\tGetHandleVerifier [0x005C8C0A+619850]\n\tGetHandleVerifier [0x005C7830+614768]\n\t(No symbol) [0x004B05FC]\n\t(No symbol) [0x004B5968]\n\t(No symbol) [0x004B5A55]\n\t(No symbol) [0x004C051B]\n\tBaseThreadInitThunk [0x766E00F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x770E7BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x770E7B8E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10384\\4189601946.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'/html/body/div[1]/div/div/div/main/div/article/div/div/p[8]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    859\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_ELEMENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    247\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/div/div/div/main/div/article/div/div/p[8]\"}\n  (Session info: chrome=108.0.5359.125)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x0051F243]\n\t(No symbol) [0x004A7FD1]\n\t(No symbol) [0x0039D04D]\n\t(No symbol) [0x003CC0B0]\n\t(No symbol) [0x003CC22B]\n\t(No symbol) [0x003FE612]\n\t(No symbol) [0x003E85D4]\n\t(No symbol) [0x003FC9EB]\n\t(No symbol) [0x003E8386]\n\t(No symbol) [0x003C163C]\n\t(No symbol) [0x003C269D]\n\tGetHandleVerifier [0x007B9A22+2655074]\n\tGetHandleVerifier [0x007ACA24+2601828]\n\tGetHandleVerifier [0x005C8C0A+619850]\n\tGetHandleVerifier [0x005C7830+614768]\n\t(No symbol) [0x004B05FC]\n\t(No symbol) [0x004B5968]\n\t(No symbol) [0x004B5A55]\n\t(No symbol) [0x004C051B]\n\tBaseThreadInitThunk [0x766E00F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x770E7BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x770E7B8E+238]\n"
     ]
    }
   ],
   "source": [
    "name=[]\n",
    "na=d.find_element(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[8]')\n",
    "for i in na:\n",
    "    nam=i.text\n",
    "    name.append(nam)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52043aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c9297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cfa26d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e2c9b99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"c00535ec568b71928e58b903f5c05cbd\", element=\"dea8f0f7-a6fe-4c53-b004-3484bceba67a\")>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c17775",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "badc7277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libabries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f9d4be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32.exe')\n",
    "d.get('http://statisticstimes.com')\n",
    "d.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a8ac038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy=d.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "economy.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "1ad6ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "india=d.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "india.get_attribute('href')\n",
    "india.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "9b34f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "state=[]\n",
    "gsdp18_19=[]\n",
    "gsdp19_20=[]\n",
    "share=[]\n",
    "gdp_billion=[]\n",
    "\n",
    "rw=d.find_elements(By.XPATH,'//tr[@role=\"row\"]')\n",
    "for i in rw[2:33]:\n",
    "    ro=i.text.split(' ')[1]\n",
    "    state.append(ro)\n",
    "for i in rw[2:33]:\n",
    "    ro=i.text.split(' ')[0]\n",
    "    rank.append(ro)\n",
    "\n",
    "for i in rw[2:33]:\n",
    "    ro=i.text.split(' ')[2]\n",
    "    gsdp19_20.append(ro)\n",
    "\n",
    "for i in rw[2:33]:\n",
    "    ro=i.text.split(' ')[3]\n",
    "    gsdp18_19.append(ro)\n",
    "for i in rw[2:33]:\n",
    "    ro=i.text.split(' ')[4]\n",
    "    share.append(ro) \n",
    "for i in rw[2:33]:\n",
    "    ro=i.text.split(' ')[5]\n",
    "    gdp_billion.append(ro)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d1a02b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>GSDP19_220</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP($ BILLION)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra</td>\n",
       "      <td>972,782</td>\n",
       "      <td>Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya</td>\n",
       "      <td>906,672</td>\n",
       "      <td>Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu</td>\n",
       "      <td>Kashmir</td>\n",
       "      <td>&amp;</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal</td>\n",
       "      <td>165,472</td>\n",
       "      <td>Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal</td>\n",
       "      <td>-</td>\n",
       "      <td>Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank         State GSDP(18-19) GSDP19_220      Share GDP($ BILLION)\n",
       "0     1   Maharashtra   2,632,792          -     13.94%        399.921\n",
       "1     2         Tamil   1,845,853       Nadu  1,630,208          8.63%\n",
       "2     3         Uttar   1,687,818    Pradesh  1,584,764          8.39%\n",
       "3     4       Gujarat   1,502,899          -      7.96%        228.290\n",
       "4     5     Karnataka   1,493,127  1,631,977      7.91%        226.806\n",
       "5     6          West   1,253,832     Bengal  1,089,898          5.77%\n",
       "6     7     Rajasthan     942,586  1,020,989      4.99%        143.179\n",
       "7     8        Andhra     972,782    Pradesh    862,957          4.57%\n",
       "8     9     Telangana     861,031    969,604      4.56%        130.791\n",
       "9    10        Madhya     906,672    Pradesh    809,592          4.29%\n",
       "10   11        Kerala     781,653          -      4.14%        118.733\n",
       "11   12         Delhi     774,870    856,112      4.10%        117.703\n",
       "12   13       Haryana     734,163    831,610      3.89%        111.519\n",
       "13   14         Bihar     530,363    611,804      2.81%         80.562\n",
       "14   15        Punjab     526,376    574,760      2.79%         79.957\n",
       "15   16        Odisha     487,805    521,275      2.58%         74.098\n",
       "16   17         Assam     315,881          -      1.67%         47.982\n",
       "17   18  Chhattisgarh     304,063    329,180      1.61%         46.187\n",
       "18   19     Jharkhand     297,204    328,598      1.57%         45.145\n",
       "19   20   Uttarakhand     245,895          -      1.30%         37.351\n",
       "20   21         Jammu     Kashmir          &          -        155,956\n",
       "21   22      Himachal     165,472    Pradesh    153,845          0.81%\n",
       "22   23           Goa      73,170     80,449      0.39%         11.115\n",
       "23   24       Tripura      49,845     55,984      0.26%          7.571\n",
       "24   25    Chandigarh      42,114          -      0.22%          6.397\n",
       "25   26    Puducherry      34,433     38,253      0.18%          5.230\n",
       "26   27     Meghalaya      33,481     36,572      0.18%          5.086\n",
       "27   28        Sikkim      28,723     32,496      0.15%          4.363\n",
       "28   29       Manipur      27,870     31,790      0.15%          4.233\n",
       "29   30      Nagaland      27,283          -      0.14%          4.144\n",
       "30   31     Arunachal           -    Pradesh     24,603          0.13%"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':rank,'State':state,'GSDP(18-19)':gsdp18_19,'GSDP19_220':gsdp19_20,'Share':share,'GDP($ BILLION)':gdp_billion})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fb474a",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "2b1686d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libabries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "5227bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32.exe')\n",
    "d.get(' https://github.com/')\n",
    "d.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "647e8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=d.find_element(By.XPATH,'//input[@data-test-selector=\"nav-search-input\"]')\n",
    "search_bar.send_keys('trending repositories')\n",
    "search_bar.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "418bb62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_titles=[]\n",
    "description=[]\n",
    "contributors=[]\n",
    "language=[]\n",
    "t=d.find_elements(By.XPATH,'//a[@class=\"v-align-middle\"]')\n",
    "for i in t:\n",
    "    to=i.text\n",
    "    rep_titles.append(to)\n",
    "dis=d.find_elements(By.XPATH,'//p[@class=\"mb-1\"]')\n",
    "for i in dis:\n",
    "    disp=i.text\n",
    "    description.append(disp)\n",
    "lan=d.find_elements(By.XPATH,'//div[@class=\"d-flex flex-wrap text-small color-fg-muted\"]')\n",
    "for i in lan:\n",
    "    lang=i.text.split('\\n')[1]\n",
    "    language.append(lang)\n",
    "cont=d.find_elements(By.XPATH,'//div[@class=\"f6 color-fg-muted mt-2\"]/a[7]')\n",
    "for i in cont:\n",
    "    con=i.text\n",
    "    contributors.append(con)                \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482821d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "82cafd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>Description</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vitalets/github-trending-repos</td>\n",
       "      <td>Track GitHub trending repositories in your fav...</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mbadry1/Trending-Deep-Learning</td>\n",
       "      <td>Top 100 trending deep learning repositories so...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QasimWani/LeetHub</td>\n",
       "      <td>Automatically sync your leetcode solutions to ...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semigradsky/trending-repositories</td>\n",
       "      <td>⭐ This is a list of repositories that were tre...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>laowch/GithubTrends</td>\n",
       "      <td>It's a GitHub Trending repositories Viewer wit...</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ophobe/trending</td>\n",
       "      <td>Dataset of trending repositories on GitHub</td>\n",
       "      <td>Updated on Aug 16, 2020Aug 16, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zhuowenli/githuber</td>\n",
       "      <td>Display Github Trending repositories on Chrome...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ecrmnn/trending-github</td>\n",
       "      <td>📈  Simple API for getting trending repositorie...</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>andygrunwald/TrendingGithub</td>\n",
       "      <td>A twitter bot (@TrendingGithub) to tweet trend...</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>andygrunwald/go-trending</td>\n",
       "      <td>Go library for accessing trending repositories...</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              titles  \\\n",
       "0     vitalets/github-trending-repos   \n",
       "1     mbadry1/Trending-Deep-Learning   \n",
       "2                  QasimWani/LeetHub   \n",
       "3  Semigradsky/trending-repositories   \n",
       "4                laowch/GithubTrends   \n",
       "5                    ophobe/trending   \n",
       "6                 zhuowenli/githuber   \n",
       "7             ecrmnn/trending-github   \n",
       "8        andygrunwald/TrendingGithub   \n",
       "9           andygrunwald/go-trending   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Track GitHub trending repositories in your fav...   \n",
       "1  Top 100 trending deep learning repositories so...   \n",
       "2  Automatically sync your leetcode solutions to ...   \n",
       "3  ⭐ This is a list of repositories that were tre...   \n",
       "4  It's a GitHub Trending repositories Viewer wit...   \n",
       "5         Dataset of trending repositories on GitHub   \n",
       "6  Display Github Trending repositories on Chrome...   \n",
       "7  📈  Simple API for getting trending repositorie...   \n",
       "8  A twitter bot (@TrendingGithub) to tweet trend...   \n",
       "9  Go library for accessing trending repositories...   \n",
       "\n",
       "                              Language  \n",
       "0                                 HTML  \n",
       "1                               Python  \n",
       "2                           JavaScript  \n",
       "3                           JavaScript  \n",
       "4                                 Java  \n",
       "5  Updated on Aug 16, 2020Aug 16, 2020  \n",
       "6                           JavaScript  \n",
       "7                           TypeScript  \n",
       "8                                   Go  \n",
       "9                                   Go  "
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'titles':rep_titles,'Description':description,'Language':language})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e936cf8",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libabries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "d331bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32.exe')\n",
    "d.get('https:/www.billboard.com/')\n",
    "d.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "4820f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart=d.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "chart.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "03714b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_chart=d.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[3]/a')\n",
    "view_chart.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "8e4303bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "na=d.find_elements(By.XPATH,'//div[@class=\"o-chart-results-list-row-container\"]')\n",
    "for i in na:\n",
    "    nam=i.text.split('\\n')[0]\n",
    "    name.append(nam)\n",
    "artist=[]\n",
    "for i in na:\n",
    "    nam=i.text.split('\\n')[1]\n",
    "    artist.append(nam)\n",
    "lawera=[]\n",
    "for i in na:\n",
    "    nam=i.text.split('\\n')[3]\n",
    "    lawera.append(nam)\n",
    "pera=[]\n",
    "for i in na:\n",
    "    nam=i.text.split('\\n')[4]\n",
    "    pera.append(nam)  \n",
    "weonch=[]\n",
    "for i in na:\n",
    "    nam=i.text.split('\\n')[5]\n",
    "    weonch.append(nam)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "369e1110",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>All I Want For Christmas Is You</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rockin' Around The Christmas Tree</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jingle Bell Rock</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A Holly Jolly Christmas</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Last Christmas</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>RE- ENTRY</td>\n",
       "      <td>Jimmie Allen</td>\n",
       "      <td>-</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>One Thing At A Time</td>\n",
       "      <td>81</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Hold Me Closer</td>\n",
       "      <td>89</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Far</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>All Mine</td>\n",
       "      <td>95</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Song name                        Artist name Last week rank Peak rank  \\\n",
       "0          1    All I Want For Christmas Is You              1         1   \n",
       "1          2  Rockin' Around The Christmas Tree              2         2   \n",
       "2          3                   Jingle Bell Rock              4         3   \n",
       "3          4            A Holly Jolly Christmas              5         4   \n",
       "4          5                     Last Christmas              6         5   \n",
       "..       ...                                ...            ...       ...   \n",
       "95        96                          RE- ENTRY   Jimmie Allen         -   \n",
       "96        97                One Thing At A Time             81        37   \n",
       "97        98                     Hold Me Closer             89         6   \n",
       "98        99                                Far             61        61   \n",
       "99       100                           All Mine             95        42   \n",
       "\n",
       "   Weeks on board  \n",
       "0              57  \n",
       "1              51  \n",
       "2              48  \n",
       "3              31  \n",
       "4              30  \n",
       "..            ...  \n",
       "95             88  \n",
       "96              3  \n",
       "97             17  \n",
       "98              2  \n",
       "99             20  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Song name':name,'Artist name':artist,'Last week rank':lawera,'Peak rank':pera,'Weeks on board':weonch})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21adfcde",
   "metadata": {},
   "source": [
    "# 7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b8180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libabries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "5023ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32.exe')\n",
    "d.get('https://www.naukri.com/hr-recruiters-consultants')\n",
    "d.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "53af1e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=d.find_element(By.XPATH,'//input[@class=\"sugInp\"]')\n",
    "search_bar.send_keys('Data Science')\n",
    "search_icon=d.find_element(By.XPATH,'//button[@id=\"qsbFormBtn\"]')\n",
    "search_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "5432ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc=d.find_element(By.XPATH,'/html/body/div[3]/div/div[1]/div/form/div[2]/div[1]/a[3]/em[2]')\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "5e28dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "company=[]\n",
    "na=d.find_elements(By.XPATH,'//span[@class=\"fl ellipsis\"]')\n",
    "for i in na[0:25]:\n",
    "    nam=i.text\n",
    "    name.append(nam)\n",
    "location=[]\n",
    "loc=d.find_elements(By.XPATH,'//small[@class=\"ellipsis\"]')\n",
    "for  i in loc[0:25]:\n",
    "    loct=i.text\n",
    "    location.append(loct)\n",
    "companys=[]\n",
    "com=d.find_elements(By.XPATH,'//a[@class=\"ellipsis\"]')\n",
    "for i in com[0:25]:\n",
    "    comp=i.text\n",
    "    companys.append(comp)\n",
    "\n",
    "skills=[]\n",
    "sk=d.find_elements(By.XPATH,'//div[@class=\"hireSec highlightable\"]')\n",
    "for i in sk[0:25]:\n",
    "    skl=i.text\n",
    "    skills.append(skl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "156a2010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>company</th>\n",
       "      <th>Skills and Role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Pune</td>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>UK - (london)</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>Trivandrum</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Indore</td>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Qa, Ui/ux, Java Developer, Java Architect, C++...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Business Intelligence, Data Warehousing, Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Office Administration, Hr Administration, tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Social Media, digital media maketing, seo, smm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vaishnavi Kudalkar</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>Data Science, Python, Data Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Priyanka Akiri</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Oracle Dba, Data Science, Data Warehousing, ET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>Bhopal</td>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Big Data, Hadoop, Data Analytics, Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sakshi Chhikara</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>React.js, Data Science, Java, Front End, Busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Pune</td>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Qlikview, Qlik Sense, Microsoft Azure, Power B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Telecalling, Client Interaction, Marketing, Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Corporate Sales, Software Development, Softwar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Data Analytics, Data Science, Machine Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>Pune</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Data Science, Machine Learning, Python, R, Dee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Big Data, Data Science, Artificial Intelligenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name                  Location  \\\n",
       "0                                    Aakash Harit                     Delhi   \n",
       "1                            shravan Kumar Gaddam  Hyderabad / Secunderabad   \n",
       "2                        MARSIAN Technologies LLP                      Pune   \n",
       "3                                    Anik Agrawal                 Ahmedabad   \n",
       "4                                    subhas patel             UK - (london)   \n",
       "5    Abhishek - Only Analytics Hiring - India and         Vadodara / Baroda   \n",
       "6   Institute for Financial Management and Resear                   Chennai   \n",
       "7                                     Balu Ramesh                Trivandrum   \n",
       "8                                   Asif Lucknowi                    Indore   \n",
       "9                                 InstaFinancials     Bengaluru / Bangalore   \n",
       "10                                Kalpana Dumpala  Hyderabad / Secunderabad   \n",
       "11                                        Mubarak     Bengaluru / Bangalore   \n",
       "12                                 Kushal Rastogi                    Mumbai   \n",
       "13                             Mahesh Babu Channa  Hyderabad / Secunderabad   \n",
       "14                             Vaishnavi Kudalkar                    Mumbai   \n",
       "15                                 Priyanka Akiri                 Hyderabad   \n",
       "16                                   Kapil Devang                    Bhopal   \n",
       "17                                Sakshi Chhikara                Chandigarh   \n",
       "18                                    Ruchi Dhote                      Pune   \n",
       "19                                  Manisha Yadav               Navi Mumbai   \n",
       "20                                    Riya Rajesh                    Cochin   \n",
       "21                           Rashmi Bhattacharjee                     Delhi   \n",
       "22                                  Faizan Kareem  Hyderabad / Secunderabad   \n",
       "23                                 Rithika dadwal                      Pune   \n",
       "24                             Sandhya Khandagale                      Pune   \n",
       "\n",
       "                                          company  \\\n",
       "0                                    Aakash Harit   \n",
       "1                            Data Science Network   \n",
       "2                            shravan Kumar Gaddam   \n",
       "3                   Shore Infotech India Pvt. Ltd   \n",
       "4                        MARSIAN Technologies LLP   \n",
       "5                        MARSIAN Technologies LLP   \n",
       "6                                    Anik Agrawal   \n",
       "7           Enerlytics Software Solutions Pvt Ltd   \n",
       "8                                    subhas patel   \n",
       "9                                 LibraryXProject   \n",
       "10   Abhishek - Only Analytics Hiring - India and   \n",
       "11     Apidel Technologies Division of Transpower   \n",
       "12  Institute for Financial Management and Resear   \n",
       "13                                           IFMR   \n",
       "14                                    Balu Ramesh   \n",
       "15                    Techvantage Systems Pvt Ltd   \n",
       "16                                  Asif Lucknowi   \n",
       "17                     Weupskill- Live Wire India   \n",
       "18                                InstaFinancials   \n",
       "19               CBL Data Science Private Limited   \n",
       "20                                Kalpana Dumpala   \n",
       "21                             Innominds Software   \n",
       "22                                        Mubarak   \n",
       "23                                       MoneyTap   \n",
       "24                                 Kushal Rastogi   \n",
       "\n",
       "                                      Skills and Role  \n",
       "0   Classic ASP Developer, Internet Marketing Prof...  \n",
       "1   .Net, Java, Data Science, Linux Administration...  \n",
       "2   Data Science, Artificial Intelligence, Machine...  \n",
       "3   Mean Stack, javascript, angularjs, mongodb, We...  \n",
       "4   Hadoop, Spark, Digital Strategy, Data Architec...  \n",
       "5   Analytics, Business Intelligence, Business Ana...  \n",
       "6                                        Data Science  \n",
       "7   Machine Learning, algorithms, Go Getter, Compu...  \n",
       "8   Technical Training, Software Development, Pres...  \n",
       "9   Software Development, It Sales, Account Manage...  \n",
       "10  Qa, Ui/ux, Java Developer, Java Architect, C++...  \n",
       "11  Business Intelligence, Data Warehousing, Data ...  \n",
       "12  Office Administration, Hr Administration, tele...  \n",
       "13  Social Media, digital media maketing, seo, smm...  \n",
       "14               Data Science, Python, Data Analytics  \n",
       "15  Oracle Dba, Data Science, Data Warehousing, ET...  \n",
       "16     Big Data, Hadoop, Data Analytics, Data Science  \n",
       "17  React.js, Data Science, Java, Front End, Busin...  \n",
       "18  Qlikview, Qlik Sense, Microsoft Azure, Power B...  \n",
       "19  Telecalling, Client Interaction, Marketing, Re...  \n",
       "20                                       Data Science  \n",
       "21  Corporate Sales, Software Development, Softwar...  \n",
       "22  Data Analytics, Data Science, Machine Learning...  \n",
       "23  Data Science, Machine Learning, Python, R, Dee...  \n",
       "24  Big Data, Data Science, Artificial Intelligenc...  "
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame({'Name':name,'Location':location,'company':companys,'Skills and Role':skills})\n",
    "df1df1=pd.DataFrame({'Namw':name,'Location':location,'comapany'})    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225df3f1",
   "metadata": {},
   "source": [
    "# 8. Scrape the details of Highest selling novels.\n",
    "\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-\n",
    "compare/\n",
    "\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406de4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libabries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "27ff09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32.exe')\n",
    "d.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')\n",
    "d.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "9a4a0537",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "head=d.find_elements(By.XPATH,'//td[@class=\"left\"]')\n",
    "for i in head:\n",
    "    list1.append(i.text)\n",
    "name=[]\n",
    "for i in range(1,500,5):\n",
    "    name.append(list1[i])\n",
    "author=[]\n",
    "for i in range(2,500,5):\n",
    "    author.append(list1[i])\n",
    "volume_sold=[]\n",
    "for i in range(3,500,5):\n",
    "    volume_sold.append(list1[i])\n",
    "publisher=[]\n",
    "for i in range(4,500,5):\n",
    "    publisher.append(list1[i])\n",
    "genre=[]\n",
    "gen=d.find_elements(By.XPATH,'//td[@class=\"last left\"]')\n",
    "for i in gen:\n",
    "    gre=i.text\n",
    "    genre.append(gre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "b384b25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Volume_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book name       Author name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume_sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.DataFrame({'Book name':name,'Author name':author,'Volume_sold':volume_sold,'Publisher':publisher,'Genre':genre})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb1ba0c",
   "metadata": {},
   "source": [
    "# 9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428535ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libabries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "58ed7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32.exe')\n",
    "d.get('https://www.imdb.com/list/ls095964455/ ')\n",
    "d.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "b7a17df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name=[]\n",
    "name=d.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]')\n",
    "for i in name:\n",
    "    ne=i.text.split('(')[0]\n",
    "    movie_name.append(ne)\n",
    "year_of_release=[]\n",
    "for i in name:\n",
    "    na=i.text.split('(')[1]\n",
    "    year_of_release.append(na)\n",
    "votes=[]\n",
    "vote=d.find_elements(By.XPATH,'//span[@name=\"nv\"]')\n",
    "for i in vote:\n",
    "    vt=i.text\n",
    "    votes.append(vt)\n",
    "runtime=[]\n",
    "ru=d.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "for i in ru:\n",
    "    rt=i.text\n",
    "    runtime.append(rt)\n",
    "rating=[]\n",
    "rat=d.find_elements(By.XPATH,'//div[@class=\"ipl-rating-widget\"]')\n",
    "for i in rat:\n",
    "    re=i.text.split('\\nRate')[0]\n",
    "    rating.append(re)\n",
    "genre=[]\n",
    "ge=d.find_elements(By.XPATH,'//span[@class=\"genre\"] ')\n",
    "for i in ge:\n",
    "    gee=i.text\n",
    "    genre.append(gee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "6672fd89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series_name</th>\n",
       "      <th>Year of release</th>\n",
       "      <th>Voting</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Rating</th>\n",
       "      <th>GENRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones</td>\n",
       "      <td>2011–2019)</td>\n",
       "      <td>2,100,254</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Stranger Things</td>\n",
       "      <td>2016– )</td>\n",
       "      <td>1,190,515</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. The Walking Dead</td>\n",
       "      <td>2010–2022)</td>\n",
       "      <td>994,233</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. 13 Reasons Why</td>\n",
       "      <td>2017–2020)</td>\n",
       "      <td>294,244</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The 100</td>\n",
       "      <td>2014–2020)</td>\n",
       "      <td>253,345</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96. Reign</td>\n",
       "      <td>2013–2017)</td>\n",
       "      <td>50,378</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97. A Series of Unfortunate Events</td>\n",
       "      <td>2017–2019)</td>\n",
       "      <td>61,989</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98. Criminal Minds</td>\n",
       "      <td>2005– )</td>\n",
       "      <td>199,956</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99. Scream: The TV Series</td>\n",
       "      <td>2015–2019)</td>\n",
       "      <td>41,715</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100. The Haunting of Hill House</td>\n",
       "      <td>2018)</td>\n",
       "      <td>247,010</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Series_name Year of release     Voting Run time  \\\n",
       "0                   1. Game of Thrones       2011–2019)  2,100,254   57 min   \n",
       "1                   2. Stranger Things          2016– )  1,190,515   51 min   \n",
       "2                  3. The Walking Dead       2010–2022)    994,233   44 min   \n",
       "3                    4. 13 Reasons Why       2017–2020)    294,244   60 min   \n",
       "4                           5. The 100       2014–2020)    253,345   43 min   \n",
       "..                                  ...             ...        ...      ...   \n",
       "95                           96. Reign       2013–2017)     50,378   42 min   \n",
       "96  97. A Series of Unfortunate Events       2017–2019)     61,989   50 min   \n",
       "97                  98. Criminal Minds          2005– )    199,956   42 min   \n",
       "98           99. Scream: The TV Series       2015–2019)     41,715   45 min   \n",
       "99     100. The Haunting of Hill House            2018)    247,010  572 min   \n",
       "\n",
       "   Rating                     GENRE  \n",
       "0     9.2  Action, Adventure, Drama  \n",
       "1     8.7    Drama, Fantasy, Horror  \n",
       "2     8.1   Drama, Horror, Thriller  \n",
       "3     7.5  Drama, Mystery, Thriller  \n",
       "4     7.6    Drama, Mystery, Sci-Fi  \n",
       "..    ...                       ...  \n",
       "95    7.4                     Drama  \n",
       "96    7.8  Adventure, Comedy, Drama  \n",
       "97    8.1     Crime, Drama, Mystery  \n",
       "98    7.1      Comedy, Crime, Drama  \n",
       "99    8.6    Drama, Horror, Mystery  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.DataFrame({'Series_name':movie_name,'Year of release':year_of_release,'Voting':votes,'Run time':runtime,'Rating':rating,'GENRE':genre})\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adac80c",
   "metadata": {},
   "source": [
    "# 10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "a14c6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libabries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "id": "68341f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=webdriver.Chrome(r'C:\\Users\\Admin\\Downloads\\chromedriver_win32.exe')\n",
    "d.get('https://archive.ics.uci.edu/ ')\n",
    "d.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "a8c681b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all=d.find_element(By.XPATH,'/html/body/table[1]/tbody/tr/td[2]/span[2]/a/font/b')\n",
    "all.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "a5b401ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "types=[]\n",
    "task=[]\n",
    "attribute=[]\n",
    "instances=[]\n",
    "noofattributes=[]\n",
    "year=[]\n",
    "table=d.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]')[1:623]\n",
    "for i in table:\n",
    "    tl=i.text\n",
    "    name.append(tl)\n",
    "table=d.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]')[1:623]\n",
    "for i in table:\n",
    "    te=i.text\n",
    "    types.append(te)\n",
    "table=d.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]')[1:623]\n",
    "for i in table:\n",
    "    te=i.text\n",
    "    task.append(te) \n",
    "table=d.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]')[1:623]\n",
    "for i in table:\n",
    "    te=i.text\n",
    "    attribute.append(te)     \n",
    "table=d.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]')[1:623]\n",
    "for i in table:\n",
    "    te=i.text\n",
    "    instances.append(te) \n",
    "table=d.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]')[1:623]\n",
    "for i in table:\n",
    "    te=i.text\n",
    "    noofattributes.append(te) \n",
    "table=d.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]')[1:623]\n",
    "for i in table:\n",
    "    te=i.text\n",
    "    year.append(te)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "26983778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(622, 622, 622, 622, 622, 622, 622)"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name),len(types),len(task),len(attribute),len(instances),len(noofattributes),len(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "1da6d860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSet Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twit...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mo...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          DataSet Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617    Influenza outbreak event prediction via Twit...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621    Image Recognition Task Execution Times in Mo...   \n",
       "\n",
       "                      Data Type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute type No of Instances No of Attributes   Year  \n",
       "0    Categorical, Integer, Real            4177                8   1995   \n",
       "1          Categorical, Integer           48842               14   1996   \n",
       "2    Categorical, Integer, Real             798               38          \n",
       "3                   Categorical           37711              294   1998   \n",
       "4    Categorical, Integer, Real             452              279   1998   \n",
       "..                           ...             ...              ...    ...  \n",
       "617               Integer, Real           75840              525   2020   \n",
       "618               Integer, Real             400               50   2020   \n",
       "619                                        1014                7   2020   \n",
       "620                        Real           10129               16   2021   \n",
       "621                        Real            4000                2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6=pd.DataFrame({'DataSet Name':name,'Data Type':types,'Task':task,'Attribute type':attribute,'No of Instances':instances,'No of Attributes':noofattributes,'Year':year})\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef555e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
